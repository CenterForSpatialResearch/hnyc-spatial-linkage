{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## supplementary run to `EXPLORE similarity labels with vs without sequence order.ipybn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from interpolation import CensusData, sequences, BlockInterpolator, CentroidInterpolator, archive, interpolation\n",
    "from sklearn.pipeline import Pipeline\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from kmodes.kmodes import KModes\n",
    "from kmodes.kprototypes import KPrototypes\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_1850 = pd.read_csv(\"../../data/dwelling_filled_sum_1850_mn_v02.csv\")\n",
    "cd_1850 = pd.read_csv(\"../../data/cd_1850_mn_20200918.csv\") #For calculating centroids\n",
    "# enumerators = pd.read_csv(\"../../data/census_1850_enumerationDetail_mn_union.csv\")\n",
    "enumerators = pd.read_csv(\"../../data/census_1850_enumerationDetail_mn_ward10.csv\")\n",
    "\n",
    "ward_col = \"CENSUS_WARD_NUM\"\n",
    "dwelling_col = \"dwelling_id\"\n",
    "block_col = \"CD_BLOCK_NUM\"\n",
    "cd_ward_col = \"CD_WARD_NUM\"\n",
    "cd_block_col = \"CD_BLOCK_NUM\"\n",
    "dwelling_num_col = \"CENSUS_DWELLING_NUM\"\n",
    "cd_address = \"CD_H_ADDRESS\"\n",
    "pagenum = \"CENSUS_PAGENUM\"\n",
    "x_col = \"CD_X\"\n",
    "y_col = \"CD_Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OBJECTID', 'CD_RECORD_ID', 'CD_INDEX', 'CD_RAW', 'CD_OCCUPATION',\n",
       "       'CD_OCCUPATION_STD', 'CD_LAST_NAME', 'CD_FIRST_NAME', 'CD_MIDDLE_NAME',\n",
       "       'CD_H_ADDRESS', 'CD_H_HOUSE_NUMBER', 'CD_H_STREET_NAME', 'CD_H_CITY',\n",
       "       'CD_WARD_NUM', 'CD_BLOCK_NUM', 'CD_X', 'CD_Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd_1850.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set clustering algo -- this is to make sure that the same clustering algorithm is used\n",
    "#for each model, to ensure that testing is accurate\n",
    "#note fitting before hand won't work for all types of clustering, for example, with agglomerative\n",
    "#clustering this isn't going to work because the algorithm doesn't have a predict method\n",
    "block_centroids = {ward:{block:interpolation.make_centroid(df_block[x_col], df_block[y_col]) for block, df_block in df.groupby(cd_block_col)} for ward,df in cd_1850.groupby(cd_ward_col)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ward10 = filled_1850[filled_1850[ward_col] == 10]\n",
    "ward10_enumerators = ward10.merge(enumerators,  how = \"left\", left_on= [ward_col, \"CENSUS_PAGENUM\"], \n",
    "                                  right_on = [ward_col, \"CENSUS_PAGENO_HOUSEHOLD\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With sequence order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "n is 5 and it's the 10th iteration\n",
      "n is 5 and it's the 10th iteration\n",
      "n is 5 and it's the 10th iteration\n",
      "failed at n=30 and g=10\n",
      "n is 5 and it's the 10th iteration\n",
      "n is 5 and it's the 10th iteration\n",
      "failed at n=40 and g=5\n",
      "failed at n=50 and g=0.1\n"
     ]
    }
   ],
   "source": [
    "### with sequence order in similarity check \n",
    "\n",
    "census_enum_seq_order = CensusData(ward10_enumerators, ward_col=ward_col, \n",
    "                             dwelling_col=dwelling_col, block_col =  block_col, \n",
    "                             x_col = x_col, y_col = y_col, pagenum = pagenum)\n",
    "census_enum_seq_order.apply_sequencing(d=0.1, enumerator_dist = True, \n",
    "                                 dwelling = True, fixed = True, distance = True)\n",
    "\n",
    "gamma_list = [0.1, 1, 5, 10, 20, 25, 40, 50]\n",
    "n_cluster_list = [30,40, 50]\n",
    "result_train_n_pro = {}\n",
    "result_test_n_pro = {}\n",
    "\n",
    "for k in n_cluster_list:\n",
    "    \n",
    "    \n",
    "    result_train_g = {}\n",
    "    result_test_g = {}  \n",
    "    model_g = {}\n",
    "    ## runn= gamma\n",
    "    for g in gamma_list:\n",
    "        \n",
    "        kpro_model = KPrototypes(n_clusters=k, init = \"random\", n_init = 1, gamma=g)\n",
    "        cate_similar_cols = [\"sequence_id\", \"dwelling_seq_id\", \"fixed_seq\", \"enum_dist_id\"]\n",
    "        cont_similar_cols = ['sequence_order_enum']\n",
    "        try:\n",
    "            census_enum_seq_order.apply_similarity(kpro_model=kpro_model, cate_sim_columns=cate_similar_cols, \n",
    "                                             cont_sim_columns=cont_similar_cols)\n",
    "        except:\n",
    "            print(f'failed at n={k} and g={g}')\n",
    "            result_train_g[g] = np.nan\n",
    "            result_test_g[g] = np.nan\n",
    "            break\n",
    "            \n",
    "        all_cols = ['CENSUS_SERIAL', 'CENSUS_AGE', 'CENSUS_PAGENUM', 'CENSUS_GENDER', 'CENSUS_RACE',\n",
    "                    \"sequence_id\", \"CENSUS_DWELLING_SIZE\",\"CENSUS_SEQ_NUM\", \"CENSUS_LABFORCE\", \"CENSUS_LINE\", \n",
    "                    \"CENSUS_MARST\", 'CENSUS_FIRST_NAME', 'CENSUS_LAST_NAME', 'CENSUS_OCCUPATION', 'CENSUS_IMPREL',\n",
    "                    \"sequence_order_enum\", 'CENSUS_DWELLING_SEQ', \"dwelling_seq_id\", \"fixed_seq\", \"enum_dist_id\", \n",
    "                    \"enum_dist_order\"]\n",
    "\n",
    "        transformer = ColumnTransformer(transformers=[('target', TargetEncoder(), all_cols), \n",
    "                                                      ('onehot', OneHotEncoder(handle_unknown='ignore'), ['similarity_label'])])\n",
    "        # define pipeline\n",
    "        pipeline = Pipeline(steps=[('preprocess', transformer), \n",
    "                                   ('classifier',XGBClassifier(colsample_bytree = 0.6, max_depth = 5, \n",
    "                                                               n_estimators = 30))])\n",
    "        interpolate_sequences_order = CentroidInterpolator(census_enum_seq_order, 10, pipeline, all_cols + ['similarity_label'],\n",
    "                                                     KMeans(5), block_centroids)\n",
    "        score, model = interpolate_sequences_order.kmeans_best(5)\n",
    "        interpolate_sequences_order.set_clustering_algo(model)\n",
    "        interpolate_sequences_order.apply_clustering(algo_fit = True)\n",
    "        # interpolate_sequences.clustervis(kmeans = True)\n",
    "\n",
    "        interpolate_sequences_order.cross_validate_model(k=5)\n",
    "    #     print(\"avg Training score:\", np.array(interpolate_sequences.train_score).mean())\n",
    "    #     print('Test score:', interpolate_sequences.test_score)\n",
    "    #     print(\"avg Test score:\", np.array(interpolate_sequences.test_score).mean())\n",
    "        result_train_g[g] = np.array(interpolate_sequences_order.train_score).mean()\n",
    "        result_test_g[g] = np.array(interpolate_sequences_order.test_score).mean()  \n",
    "    \n",
    "    result_train_n_pro[k] = result_train_g\n",
    "    result_test_n_pro[k] = result_test_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "a = (result_train_n_pro, result_test_n_pro)\n",
    "\n",
    "with open('../../result_2.pickle', 'wb') as handle:\n",
    "    pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "d:  0.1\n",
      "n is 5 and it's the 10th iteration\n",
      "n is 5 and it's the 10th iteration\n",
      "n is 5 and it's the 10th iteration\n",
      "n is 5 and it's the 10th iteration\n",
      "n is 5 and it's the 10th iteration\n",
      "n is 5 and it's the 10th iteration\n",
      "n is 5 and it's the 10th iteration\n",
      "n is 5 and it's the 10th iteration\n"
     ]
    }
   ],
   "source": [
    "### with sequence order in similarity check \n",
    "\n",
    "census_enum_seq_order = CensusData(ward10_enumerators, ward_col=ward_col, \n",
    "                             dwelling_col=dwelling_col, block_col =  block_col, \n",
    "                             x_col = x_col, y_col = y_col, pagenum = pagenum)\n",
    "census_enum_seq_order.apply_sequencing(d=0.1, enumerator_dist = True, \n",
    "                                 dwelling = True, fixed = True, distance = True)\n",
    "\n",
    "gamma_list = [0.1, 1, 5, 10, 20, 25, 40, 50]\n",
    "n_cluster_list = [20]\n",
    "result_train_n_pro = {}\n",
    "result_test_n_pro = {}\n",
    "\n",
    "for k in n_cluster_list:\n",
    "    \n",
    "    \n",
    "    result_train_g = {}\n",
    "    result_test_g = {}  \n",
    "    model_g = {}\n",
    "    ## runn= gamma\n",
    "    for g in gamma_list:\n",
    "        \n",
    "        kpro_model = KPrototypes(n_clusters=k, init = \"random\", n_init = 1, gamma=g)\n",
    "        cate_similar_cols = [\"sequence_id\", \"dwelling_seq_id\", \"fixed_seq\", \"enum_dist_id\"]\n",
    "        cont_similar_cols = ['sequence_order_enum']\n",
    "        try:\n",
    "            census_enum_seq_order.apply_similarity(kpro_model=kpro_model, cate_sim_columns=cate_similar_cols, \n",
    "                                             cont_sim_columns=cont_similar_cols)\n",
    "        except:\n",
    "            print(f'failed at n={k} and g={g}')\n",
    "            result_train_g[g] = np.nan\n",
    "            result_test_g[g] = np.nan\n",
    "            break\n",
    "            \n",
    "        all_cols = ['CENSUS_SERIAL', 'CENSUS_AGE', 'CENSUS_PAGENUM', 'CENSUS_GENDER', 'CENSUS_RACE',\n",
    "                    \"sequence_id\", \"CENSUS_DWELLING_SIZE\",\"CENSUS_SEQ_NUM\", \"CENSUS_LABFORCE\", \"CENSUS_LINE\", \n",
    "                    \"CENSUS_MARST\", 'CENSUS_FIRST_NAME', 'CENSUS_LAST_NAME', 'CENSUS_OCCUPATION', 'CENSUS_IMPREL',\n",
    "                    \"sequence_order_enum\", 'CENSUS_DWELLING_SEQ', \"dwelling_seq_id\", \"fixed_seq\", \"enum_dist_id\", \n",
    "                    \"enum_dist_order\"]\n",
    "\n",
    "        transformer = ColumnTransformer(transformers=[('target', TargetEncoder(), all_cols), \n",
    "                                                      ('onehot', OneHotEncoder(handle_unknown='ignore'), ['similarity_label'])])\n",
    "        # define pipeline\n",
    "        pipeline = Pipeline(steps=[('preprocess', transformer), \n",
    "                                   ('classifier',XGBClassifier(colsample_bytree = 0.6, max_depth = 5, \n",
    "                                                               n_estimators = 30))])\n",
    "        interpolate_sequences_order = CentroidInterpolator(census_enum_seq_order, 10, pipeline, all_cols + ['similarity_label'],\n",
    "                                                     KMeans(5), block_centroids)\n",
    "        score, model = interpolate_sequences_order.kmeans_best(5)\n",
    "        interpolate_sequences_order.set_clustering_algo(model)\n",
    "        interpolate_sequences_order.apply_clustering(algo_fit = True)\n",
    "        # interpolate_sequences.clustervis(kmeans = True)\n",
    "\n",
    "        interpolate_sequences_order.cross_validate_model(k=5)\n",
    "    #     print(\"avg Training score:\", np.array(interpolate_sequences.train_score).mean())\n",
    "    #     print('Test score:', interpolate_sequences.test_score)\n",
    "    #     print(\"avg Test score:\", np.array(interpolate_sequences.test_score).mean())\n",
    "        result_train_g[g] = np.array(interpolate_sequences_order.train_score).mean()\n",
    "        result_test_g[g] = np.array(interpolate_sequences_order.test_score).mean()  \n",
    "    \n",
    "    result_train_n_pro[k] = result_train_g\n",
    "    result_test_n_pro[k] = result_test_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "a = (result_train_n_pro, result_test_n_pro)\n",
    "\n",
    "with open('../../result_3.pickle', 'wb') as handle:\n",
    "    pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
